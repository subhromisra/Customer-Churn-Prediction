{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "Each row represents a customer, each column contains attributes related to customer demographics and previous transactions with the bank.\n",
    "\n",
    "A Bank wants to take care of customer retention for their product; savings accounts. The bank wants you to identify customers likely to churn balances below the minimum balance. You have the customers information such as age, gender, demographics along with their transactions with the bank. Your task as a data scientist would be to predict the propensity to churn for each customer.\n",
    "\n",
    "\n",
    "## Data Dictionary\n",
    "\n",
    "There are multiple variables in the dataset which can be cleanly divided in 3 categories:\n",
    "\n",
    "### Demographic information about customers\n",
    "\n",
    "<b>customer_id</b> - Customer id\n",
    "\n",
    "<b>vintage</b> - Vintage of the customer with the bank in number of days\n",
    "\n",
    "<b>age</b> - Age of customer\n",
    "\n",
    "<b>gender</b> - Gender of customer\n",
    "\n",
    "<b>dependents</b> - Number of dependents\n",
    "\n",
    "<b>occupation</b> - Occupation of the customer \n",
    "\n",
    "<b>city</b> - City of customer (anonymised)\n",
    "\n",
    "\n",
    "### Bank Related Information for customers\n",
    "\n",
    "\n",
    "<b>customer_nw_category</b> - Net worth of customer (3:Low 2:Medium 1:High)\n",
    "\n",
    "<b>branch_code</b> - Branch Code for customer account\n",
    "\n",
    "<b>days_since_last_transaction</b> - No of Days Since Last Credit in Last 1 year\n",
    "\n",
    "\n",
    "### Transactional Information\n",
    "\n",
    "<b>current_balance</b> - Balance as of today\n",
    "\n",
    "<b>previous_month_end_balance</b> - End of Month Balance of previous month\n",
    "\n",
    "\n",
    "<b>average_monthly_balance_prevQ</b> - Average monthly balances (AMB) in Previous Quarter\n",
    "\n",
    "<b>average_monthly_balance_prevQ2</b> - Average monthly balances (AMB) in previous to previous quarter\n",
    "\n",
    "<b>percent_change_credits</b> - Percent Change in Credits between last 2 quarters\n",
    "\n",
    "<b>current_month_credit</b> - Total Credit Amount current month\n",
    "\n",
    "<b>previous_month_credit</b> - Total Credit Amount previous month\n",
    "\n",
    "<b>current_month_debit</b> - Total Debit Amount current month\n",
    "\n",
    "<b>previous_month_debit</b> - Total Debit Amount previous month\n",
    "\n",
    "<b>current_month_balance</b> - Average Balance of current month\n",
    "\n",
    "<b>previous_month_balance</b> - Average Balance of previous month\n",
    "\n",
    "<b>churn</b> - Average balance of customer falls below minimum balance in the next quarter (1/0)\n",
    "\n",
    "\n",
    "Wow, we can already see there are many features in the data dictionary which we included in our hypothesis.\n",
    "\n",
    "Now, we will begin the exploratory analysis of the dataset. Note that here I have used a popular visualization library called <b>Seaborn</b> which we covered in a previous module. Seaborn is library that is easy to use and has functionality to plot a variety of plots with few lines of code. \n",
    "* Here is the link to documentation for Seaborn: https://seaborn.pydata.org/index.html. \n",
    "* You can also go through this article for a quick overview on visualization and Seaborn: https://www.analyticsvidhya.com/blog/2015/04/comprehensive-guide-data-exploration-sas-using-python-numpy-scipy-matplotlib-pandas/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Packages\n",
    "Let us load the packages needed for visualization and exploratory analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "sns.set(style=\"white\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data\n",
    "Loading the csv as a dataframe and checking structure of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File churn_prediction.csv does not exist: 'churn_prediction.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-24079c574305>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"churn_prediction.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    674\u001b[0m         )\n\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1114\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File churn_prediction.csv does not exist: 'churn_prediction.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"churn_prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have data for 28382 customers with 22 columns. So, essentially we have 21 features and 1 target column which is churn. Let us quickly look at the values for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright. Here, we have a mix of categorical, numerical and ordinal variables as shown. There are missing values also in some of the features and we would treat them as a part of preprocessing step when we build the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Target Exploration</h3>\n",
    "\n",
    "We are trying to predict if the client's account balance drops below the minimum balance prescribed for the customer. \n",
    "\n",
    "Clearly, this is a binary classification problem. Let's look at the target variable and find out how many customers are in the churn category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.catplot(y=\"churn\", kind=\"count\", data=df, height=2.6, aspect=2.5, orient='h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['churn'].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical features\n",
    "\n",
    "Let us look at the numerical features. From the description provided in the data dictionary and cell 8, we can see that we have the following numerical features. Let us quickly describe them to check the following:\n",
    "\n",
    "* Count: Can be used to check for missing value count\n",
    "* Mean: Mean of the variable\n",
    "* Standard Deviation: Standard deviation of the variable\n",
    "* Minimum: Minimum value of the variable\n",
    "* Quantile values: 25, 50 (median) & 75% quantiles of the variable\n",
    "* Maximum: Maximum value of the variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we will not directly used dtypes function to identify numerical columns but rather used business sense to select numerical features as we have seen from a smaple record, branch code and city code actually represent categories and not some meaningful numerical value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown dtypes function puts city and branch code features in the numerical category but that is not the intention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = ['customer_id', 'vintage', 'age', 'dependents', \n",
    "       'customer_nw_category', 'days_since_last_transaction', 'current_balance',\n",
    "       'previous_month_end_balance', 'average_monthly_balance_prevQ', 'average_monthly_balance_prevQ2',\n",
    "       'current_month_credit',\n",
    "       'previous_month_credit', 'current_month_debit', 'previous_month_debit',\n",
    "       'current_month_balance', 'previous_month_balance']\n",
    "df[numerical_cols].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets list down a few key observations:\n",
    "\n",
    "* Customer ID here is just an id variable identifying a unique customer and has values between 1 and 30301\n",
    "* On an average, a customer from this set has been with the bank for 2400 days or around 6.5 years\n",
    "* On an average, a customer has less than 1 dependent and has an average age of 48 years\n",
    "* A general trend on variables which are related to balances have a wide range with huge outliers, it will key to observe these outliers\n",
    "* Most of the customers lie in category 2 or 3 for net worth and have on an average done the last transaction 70 days ago. Now the high net worth customers (Category) must have high credit, debit and balance values. Let's verify this using data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer Net worth Category &  Balance Features\n",
    "\n",
    "We will use a groupby function to check the mean values of balance features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['current_balance',\n",
    "       'previous_month_end_balance', 'average_monthly_balance_prevQ', 'average_monthly_balance_prevQ2',\n",
    "        'current_month_credit','previous_month_credit', 'current_month_debit', 'previous_month_debit',\n",
    "       'current_month_balance', 'previous_month_balance']\n",
    "df.groupby(['customer_nw_category'])[cols].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there is clear consistency here as mean values of balance features and the credit/debit features have higher values for net worth category 1 and lower value for net worth categories 2 & 3.\n",
    "\n",
    "The bulk of features are comprised of balance and credit debit features. Let us explore them in detail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balance & Credit/Debit Features\n",
    "\n",
    "We will start by looking at average balance in the current month. We will use a histogram to check its distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average Monthly Balance Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df['current_month_balance'], kde = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the huge outliers in both positive and negative directions, it is very difficult to derive insights from this plot. \n",
    "\n",
    "* In this case, we could convert such columns to log and then check the distributions. \n",
    "* However, since there are negative values, it cannot be a direct log conversion as log of negative numbers is not defined.\n",
    "* To tackle this, we add a positive constant within the log as a correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To account for negative values we add a constant value within log\n",
    "temp = np.log(df['current_month_balance'] + 6000) \n",
    "\n",
    "sns.distplot(temp, kde = False, bins = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can see more clearly that this is a right skewed feature and we have much more clarity on its distribution. Let us use subplot to quickly look at more numerical features together and see trends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Features\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(16, 6))\n",
    "xmin = 7\n",
    "xmax = 16\n",
    "# Current Month Average Balance\n",
    "temp = np.log(df['current_month_balance'] + 6000) # To account for negative values we add a constant value within log\n",
    "ax1.set_xlim([xmin,xmax])\n",
    "ax1.set(xlabel='log of average balance of current month')\n",
    "sns.distplot(temp, kde = False, bins = 200, ax = ax1)\n",
    "\n",
    "\n",
    "# Previous month average balance\n",
    "temp = np.log(df['previous_month_balance'] + 6000) # To account for negative values we add a constant value within log\n",
    "ax2.set_xlim([xmin,xmax])\n",
    "ax2.set(xlabel='log of average balance of previous month')\n",
    "sns.distplot(temp, kde = False, bins = 200, ax = ax2)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Current Balance today vs Average Monthly Balance in current month"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected the average monthly balance for both months are quite similar and have right skewed histograms as shown. Now let us compare the current month average balance vs current balance as of today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical Features\n",
    "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(16, 6))\n",
    "xmin = 7\n",
    "xmax = 16\n",
    "# Current Month Average Balance\n",
    "temp = np.log(df['current_month_balance'] + 6000) # To account for negative values we add a constant value within log\n",
    "ax1.set_xlim([xmin,xmax])\n",
    "#ax1.set(xlabel='log of average balance of current month')\n",
    "sns.distplot(temp, kde = False, bins = 200, ax = ax1)\n",
    "\n",
    "\n",
    "# Current End of month average balance\n",
    "temp = np.log(df['current_balance'] + 6000) # To account for negative values we add a constant value within log\n",
    "ax2.set_xlim([xmin,xmax])\n",
    "#ax2.set(xlabel='log of month end balance of current  month')\n",
    "sns.distplot(temp, kde = False, bins = 200, ax = ax2)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Here, we can see that the distribution for both lie in almost the same interval, however, there are larger number of values for current balance just below 9 which might have been contributed by the churning customers. \n",
    "\n",
    "* It might be a good idea to create a feature which is the difference of these 2 variables during the model building process.\n",
    "\n",
    "* Students are encouraged to do more univariate analysis on other balances and check distributions to find similar insights. \n",
    "\n",
    "Next, in order to understand which of these features might be important to predict the churn, we will do a bivariate analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate Analysis\n",
    "\n",
    "Now, we will check the relationship of the numeric variables along with the target. Again conversion to log is important here as we have a lot of outliers and visualization will be difficult for it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Churn vs Current & Previous month balances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "balance_cols = ['current_balance','previous_month_end_balance',\n",
    "                'current_month_balance', 'previous_month_balance']\n",
    "df1 = pd.DataFrame()\n",
    "\n",
    "for i in balance_cols:\n",
    "    df1[str('log_')+ i] = np.log(df[i] + 6000)\n",
    "\n",
    "log_balance_cols = df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['churn'] = df['churn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the brilliant pairplot function from Seaborn which supports displaying relationship between multiple variables. It displays the scatter plot between a pair of feature and also displays the distribution\n",
    "\n",
    "Here I have included the following:\n",
    "* Log of current balance & previous month end balance\n",
    "* Log of average monthly balance of current and previous month\n",
    "* Churn is represented by the color here (Orange - Churn, Blue - Not Churn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(df1,vars=log_balance_cols, hue = 'churn',plot_kws={'alpha':0.1})\n",
    "df1_no_churn = df1[df1['churn'] == 0]\n",
    "sns.pairplot(df1_no_churn,vars=log_balance_cols,plot_kws={'alpha':0.1})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(df1,vars=log_balance_cols, hue = 'churn',plot_kws={'alpha':0.1})\n",
    "df1_churn = df1[df1['churn'] == 1]\n",
    "sns.pairplot(df1_churn,vars=log_balance_cols,plot_kws={'alpha':0.1})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df1,vars=log_balance_cols,hue ='churn',plot_kws={'alpha':0.1})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution for these features look similar. We can make the following conclusions from this:\n",
    "* There is high correlation between the previous and current month balances which is expected\n",
    "* The lower balances tend to have higher number of churns which is clear from the scatter plots\n",
    "* Distribution for the balances are all right skewed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credit and Debits for current and previous months\n",
    "\n",
    "Total credit and debit amounts for the current and previous can be clubbed into the same category. Let us again use the pair plot to check distributions and scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_dr_cols = ['current_month_credit','previous_month_credit', \n",
    "              'current_month_debit', 'previous_month_debit']\n",
    "df1 = pd.DataFrame()\n",
    "\n",
    "for i in cr_dr_cols:\n",
    "    df1[str('log_')+ i] = np.log(df[i])\n",
    "\n",
    "log_dr_cr_cols = df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['churn'] = df['churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df1,vars=log_dr_cr_cols, hue = 'churn',plot_kws={'alpha':0.5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both credit and debit patterns show significant difference in distributions for churned and non churned customers.\n",
    "* Bimodal distribution/Double Bell Curve shows that there are 2 different types of customers with 2 brackets of credit and debit. Now, during the modeling phase, these could be considered as a seperate set of customers\n",
    "* For debit values, we see that there is a significant difference in the distribution for churn and non churn and it might be turn out to be an important feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Average monthly balance of previous and previous to previous quarters\n",
    "\n",
    "Now, these 2 variables present deeper historical transactions and would help in understanding the trend during the last 2 quarters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_cols = ['average_monthly_balance_prevQ', 'average_monthly_balance_prevQ2']\n",
    "df1 = pd.DataFrame()\n",
    "\n",
    "for i in q_cols:\n",
    "    df1[str('log_')+ i] = np.log(df[i] + 17000)\n",
    "\n",
    "log_q_cols = df1.columns\n",
    "df1['churn'] = df['churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df1,vars=log_q_cols, hue = 'churn',plot_kws={'alpha':0.5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributions do not have much difference when it comes to churn. \n",
    "\n",
    "\n",
    "However, there are some high negative values in the previous to previous quarters due to which there appears to be a lateral shift. However, if you look at the x-axis, it is still at the same scale for both features.\n",
    "\n",
    "Removing the extreme outliers from the data using the 1 and 99th percentile would help us look at the correct distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 1st and 99th percentile and plot\n",
    "\n",
    "df2 = df[['average_monthly_balance_prevQ', 'average_monthly_balance_prevQ2']]\n",
    "\n",
    "low = .01\n",
    "high = .99\n",
    "quant_df = df2.quantile([low, high])\n",
    "print(quant_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.apply(lambda x: x[(x>quant_df.loc[low,x.name]) & \n",
    "                                    (x < quant_df.loc[high,x.name])], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_cols = ['average_monthly_balance_prevQ', 'average_monthly_balance_prevQ2']\n",
    "df1 = pd.DataFrame()\n",
    "\n",
    "for i in q_cols:\n",
    "    df1[str('log_')+ i] = np.log(df3[i] + 17000)\n",
    "\n",
    "log_q_cols = df1.columns\n",
    "df1['churn'] = df['churn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df1,vars=log_q_cols, hue = 'churn',plot_kws={'alpha':0.5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can clearly see that the distributions are very similar for both the variables and and non churning customers have higher average monthly balances in previous 2 quarters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demographics and Bank Related Information for customers\n",
    "\n",
    "Revisiting the description for numerical demographic & Bank related customer variables we have:\n",
    "\n",
    "#### Numerical:\n",
    "\n",
    "<b>vintage</b> - Vintage of the customer with the bank in number of days\n",
    "\n",
    "<b>age</b> - Age of customer\n",
    "\n",
    "<b>days_since_last_transaction</b> - No of Days Since Last Credit in Last 1 year\n",
    "\n",
    "#### Ordinal:\n",
    "\n",
    "<b>dependents</b> - Number of dependents\n",
    "\n",
    "<b>customer_nw_category</b> - Net worth of customer (3:Low 2:Medium 1:High)\n",
    "\n",
    "KDE plot can be used for numerical variables on the same axis to quickly compare the distributions for churning and non churning customers. It basically plots the approximate churn rate against each normal variable. This is exactly similar to what we did in the pairplot with distributions but here we would look at them separately since they represent entirely different variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Days Since Last Transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KDE Plot Smoothens out even if there are no values for a value\n",
    "def kdeplot(feature):\n",
    "    plt.figure(figsize=(9, 4))\n",
    "    plt.title(\"KDE Plot for {}\".format(feature))\n",
    "    ax0 = sns.kdeplot(df[df['churn'] == 0][feature].dropna(), color= 'dodgerblue', label= 'Churn - 0')\n",
    "    ax1 = sns.kdeplot(df[df['churn'] == 1][feature].dropna(), color= 'orange', label= 'Churn - 1')\n",
    "\n",
    "kdeplot('days_since_last_transaction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no significant difference between the distributions for churning and non churning customers when it comes to days since last transaction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age & Vintage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdeplot('age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, age also does not significantly affect the churning rate. However, customers above 80 years of age less likely to churn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kdeplot('vintage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most frequent vintage values, the churning customers are slightly higher, while for higher values of vintage, we have mostly non churning customers which is in sync with the age variable "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Categorical features</h2>\n",
    "\n",
    "This dataset has 4 categorical features (gender, occupation, city and branch code) as can be inferred from the data dictionary. Now let us have a look at the the number of unique values for each of them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['gender', 'occupation', 'city','branch_code']\n",
    "\n",
    "for i in range(0,len(cat_cols)):\n",
    "    print(str(cat_cols[i]) + \" - Number of Unique Values: \" + str(df[cat_cols[i]].nunique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, there are a large number of unique values for branch code and city. Gender has 2 unique values while occupation has 7. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate Analysis\n",
    "\n",
    "Let us look at each categorical feature and check distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = sns.color_palette()\n",
    "\n",
    "int_level = df['gender'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(int_level.index, int_level.values, alpha=0.8, color=color[1])\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('Gender', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amongst the customers, we have more males than females here. Lets check occupation now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = sns.color_palette()\n",
    "\n",
    "int_level = df['occupation'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(int_level.index, int_level.values, alpha=0.8, color=color[1])\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('Occupation', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the customers are self employed, followed by salaried account holders, retired custumors and very low number of companies.\n",
    "\n",
    "Now, branch code and city code have a lot of unique values and direct visualization will be difficult. Lets see how:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### City Code & Branch Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color = sns.color_palette()\n",
    "\n",
    "int_level = df['city'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(int_level.index, int_level.values, alpha=0.8, color=color[1])\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('City', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us have a look at the frequencies of the top city codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['city'].value_counts().head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert city variable wrt degree of number of customers\n",
    "df['city_bin'] = df['city'].copy()\n",
    "counts = df.city.value_counts()\n",
    "df.city_bin[df['city'].isin(counts[counts > 900].index)] = 3\n",
    "df.city_bin[df['city'].isin(counts[counts < 900].index) & df['city_bin'].isin(counts[counts >= 350].index)] = 2\n",
    "df.city_bin[df['city'].isin(counts[counts < 350].index) & df['city_bin'].isin(counts[counts >= 100].index)] = 1\n",
    "df.city_bin[df['city'].isin(counts[counts < 100].index)] = 0\n",
    "\n",
    "df['city_bin'] = pd.to_numeric(df['city_bin'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_level = df['city_bin'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(int_level.index, int_level.values, alpha=0.8, color=color[1])\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('city bins', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 major categories here. Cities with more than 900 occurances and with less than 100 occurances. Similarly we can create bins for branch id and have a look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['branch_code'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert city variable wrt degree of number of customers\n",
    "df['branch_bin'] = df['branch_code'].copy()\n",
    "counts = df.branch_code.value_counts()\n",
    "df.branch_bin[df['branch_code'].isin(counts[counts >= 100].index)] = 2\n",
    "df.branch_bin[df['branch_code'].isin(counts[counts < 100].index) & df['branch_bin'].isin(counts[counts >= 50].index)] = 1\n",
    "df.branch_bin[df['branch_code'].isin(counts[counts < 50].index)] = 0\n",
    "\n",
    "df['branch_bin'] = pd.to_numeric(df['branch_bin'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['branch_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_level = df['branch_bin'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(int_level.index, int_level.values, alpha=0.8, color=color[1])\n",
    "plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "plt.xlabel('branch bins', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So creating brackets/bins on the basis of frequency is a good idea to quickly analyse a variable with high number of categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, Let us look at some bivariate analysis for categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate Analysis\n",
    "\n",
    "Lets define a function to quickly compare churn rates for different categories in each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def barplot_percentages(feature):\n",
    "    #fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(16, 6))\n",
    "    ax1 = df.groupby(feature)['churn'].value_counts(normalize=True).unstack()\n",
    "    ax1.plot(kind='bar', stacked='True')\n",
    "    int_level = df[feature].value_counts()\n",
    "\n",
    "    plt.figure(figsize=(8,4))\n",
    "    sns.barplot(int_level.index, int_level.values, alpha=0.8, color=color[1])\n",
    "    plt.ylabel('Number of Occurrences', fontsize=12)\n",
    "    plt.xlabel(str(feature), fontsize=12)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_percentages(\"gender\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does not look like a very significant variable as the ratio of churned customers and others is very similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Occupation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_percentages(\"occupation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Self Employed and salaried have higher churn rate and are the major categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Branch Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_percentages(\"branch_bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### City Bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_percentages(\"city_bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we see significant difference for different occupations and certainly would be interesting to use as a feature for prediction of churn. However, city and branch codes have little difference amongst the different types of branches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dependents'][df['dependents'] > 3] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_percentages(\"dependents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most customers have no dependents and hence this variable in itself has low variance so it is of little significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Customer Net worth Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "barplot_percentages(\"customer_nw_category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not much difference in customer net worth category when it comes to churn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlation Heatmap\n",
    "\n",
    "Lastly, we will look at the correlation heatmap to check what all variables are correlated and to what extent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "df.drop(['customer_id'],\n",
    "        axis=1, inplace=True)\n",
    "corr = df.apply(lambda x: pd.factorize(x)[0]).corr()\n",
    "ax = sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, \n",
    "                 linewidths=.2, cmap=\"YlGnBu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The balance features are highly correlated as can be seen from the plot\n",
    "* Other variables have correlations but on the lower side\n",
    "* Debit values have the highest correlation amongst the balance features\n",
    "* Interestingly vintage has a considerable correlation with all the balance features which actually makes sense since older customers will tend to have higher balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Average customer Profile\n",
    "Overall a customer at this bank:\n",
    "* has no dependents\n",
    "* has been a customer for last 6 years\n",
    "* predominantly male\n",
    "* either self employed or salaried customer\n",
    "\n",
    "#### Conclusion for Churn\n",
    "* From the sample, around 17% customers are churning\n",
    "* Current balance and average monthly balance values have a left skewed distribution as observed from the histogram\n",
    "* No significant difference in distributions for average monthly balance and month end balances\n",
    "* Bimodal distribution/Double Bell Curve shows that there are 2 different types of customers with 2 brackets of credit and debit. Now, during the modeling phase, these could be considered as a seperate set of customers\n",
    "* For debit values, we see that there is a significant difference in the distribution for churn and non churn and it might be turn out to be an important feature\n",
    "* For most frequent vintage values, the churning customers are slightly higher, while for higher values of vintage, we have mostly non churning customers which is in sync with the age variable \n",
    "* Gender does not look like a very significant variable as the ratio of churned customers and others is very similar\n",
    "* Self Employed and salaried have higher churn rate and are the most frequently occuring categories.\n",
    "* Not much difference in customer net worth category when it comes to churn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
